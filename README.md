A russian version of [original](https://github.com/jhancock532/imaginary-people/) research about llm bias.

This version contains answers from GigaChat:1.0.26.15; Llama3.1:8b; T-lite-instruct-0.1-abliterated.Q8_0; YandexGPT Lite 22.05.2024

The scripts to load the llm responses live in the `scripts` directory, as well as all the LLM responses, and how Haiku processed those responses. If you'd like to see some odd token salad, look at the glitched Phi3.5 responses...

## Running the Next app

```bash
fnm use # or nvm use, basically use node version 20
npm install
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!
